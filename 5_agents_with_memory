1. Short-Term Memory (BufferMemory)

Add ConversationBufferMemory to your agent so it can remember the last few exchanges.
from langchain.memory import ConversationBufferMemory
memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

Pass this memory to your agent

from langchain.agents import AgentType, initialize_agent
from langchain.prompts import MessagesPlaceholder
from langchain_core.prompts import ChatPromptTemplate

prompt = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful assistant. Use the tools if needed."),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "{input}")
])

agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,
    memory=memory,
    verbose=True,
    agent_kwargs={
        "extra_prompt_messages": [MessagesPlaceholder(variable_name="chat_history")]
    }
)

Long-Term Memory (VectorStoreRetrieverMemory)
This allows the agent to recall older information beyond the current session.

from langchain.memory import VectorStoreRetrieverMemory
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings

embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vectorstore = Chroma(persist_directory="chroma_store", embedding_function=embedding)

memory = VectorStoreRetrieverMemory(retriever=vectorstore.as_retriever())

In your running agent, try the following back-to-back queries:

"Who is Rudra?"

"What is his address?"

"Where does he work?"

